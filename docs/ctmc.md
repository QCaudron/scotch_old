Title: Continuous-time Markov Chains



# Markov Processes

Markov chains are stochastic processes which exist in some state, and 
