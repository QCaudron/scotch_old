# Markov Processes

Markov chains are stochastic processes which exist in some state, and 
